{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from paus_utils import w_central, z_NB\n",
    "\n",
    "from jpasLAEs.utils import flux_to_mag\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'W3'\n",
    "savedir = '/home/alberto/almacen/PAUS_data/LF_corrections'\n",
    "\n",
    "nb_min, nb_max = 0, 18\n",
    "\n",
    "with open(f'{savedir}/mock_dict_{field_name}_nb{nb_min}-{nb_max}.pkl', 'rb') as f:\n",
    "    mock_dict = pickle.load(f)\n",
    "\n",
    "del mock_dict['SFG']\n",
    "# del mock_dict['GAL_artifact']\n",
    "\n",
    "# print(mock_dict['GAL_artifact'].keys())\n",
    "print(mock_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the minimum number of candidates to set the set length\n",
    "N_candidates_list = []\n",
    "for mock_name, mock in mock_dict.items():\n",
    "    z_phot = z_NB(mock['lya_NB'])\n",
    "    nice_z = np.abs(mock['zspec'] - z_phot) < 0.12\n",
    "\n",
    "    if mock_name in ['QSO_LAEs_loL', 'QSO_LAEs_hiL']:\n",
    "        N_candidates_list.append(sum(mock['nice_lya_0'][nice_z]))\n",
    "    else:\n",
    "        N_candidates_list.append(sum(mock['nice_lya_0']))\n",
    "\n",
    "set_len = np.min(N_candidates_list)\n",
    "print(N_candidates_list)\n",
    "print(f'{set_len=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the set for each class\n",
    "tt_set = None\n",
    "labels = None\n",
    "rmag = None\n",
    "zspec = None\n",
    "zphot = None\n",
    "L_Arr = None\n",
    "\n",
    "nice_z_list = []\n",
    "\n",
    "for mock_name, mock in mock_dict.items():\n",
    "    mock_len = len(mock['zspec'])\n",
    "    nice_lya = mock['nice_lya_0']\n",
    "\n",
    "    z_phot = z_NB(mock['lya_NB'])\n",
    "    nice_z = np.abs(np.array(mock['zspec']) - z_phot) < 0.12\n",
    "\n",
    "    np.random.seed(299792458)\n",
    "    selection = np.random.choice(np.arange(mock_len)[nice_lya], set_len,\n",
    "                                 replace=False)\n",
    "    this_set = np.hstack([\n",
    "        mock['flx'][:40, selection].T * 1e17, # NBs\n",
    "        mock['lya_NB'][selection].reshape(-1, 1),\n",
    "        mock['r_mag'][selection].reshape(-1, 1),\n",
    "        mock['flx'][40:45, selection].T * 1e17, # BBs\n",
    "    ])\n",
    "\n",
    "    if tt_set is None:\n",
    "        tt_set = this_set\n",
    "        this_rmag = flux_to_mag(mock['flx'][-4, selection], w_central[-4])\n",
    "        rmag = this_rmag\n",
    "        zspec = mock['zspec'][selection]\n",
    "        L_Arr = mock['L_lya'][selection]\n",
    "        zphot = z_NB(mock['lya_NB'])[selection]\n",
    "    else:\n",
    "        tt_set = np.vstack([tt_set, this_set])\n",
    "\n",
    "        this_rmag = flux_to_mag(mock['flx'][-4, selection], w_central[-4])\n",
    "        rmag = np.concatenate([rmag, this_rmag])\n",
    "        zspec = np.concatenate([zspec, mock['zspec'][selection]])\n",
    "        L_Arr = np.concatenate([L_Arr, mock['L_lya'][selection]])\n",
    "        zphot = np.concatenate([zphot, z_NB(mock['lya_NB'])[selection]])\n",
    "\n",
    "    nice_z_list.append(nice_z[selection])\n",
    "\n",
    "\n",
    "label_names = []\n",
    "labels_list = [1, 2, 2, 4]\n",
    "for j in range(len(mock_dict)):\n",
    "    i = labels_list[j]\n",
    "\n",
    "    this_labels = np.ones(set_len).astype(int) * i\n",
    "\n",
    "    mock_name = list(mock_dict.keys())[j]\n",
    "    print(f'{i} for {mock_name}')\n",
    "\n",
    "    if mock_name in ['QSO_LAEs_loL', 'QSO_LAEs_hiL']:\n",
    "        this_labels[~nice_z_list[j]] = 1\n",
    "\n",
    "    if labels is None:\n",
    "        labels = this_labels\n",
    "    else:\n",
    "        labels = np.concatenate([labels, this_labels])\n",
    "    label_names.append(mock_name)\n",
    "label_names.append('?')\n",
    "\n",
    "\n",
    "print()\n",
    "for lb in [1, 2, 4, 5]:\n",
    "    print(f'{lb}: {sum(labels == lb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "split_seed = 299792458\n",
    "x_train, x_test, y_train, y_test =\\\n",
    "    model_selection.train_test_split(tt_set, labels, test_size=0.2,\n",
    "                                     random_state=split_seed)\n",
    "\n",
    "## Pre-processing ##\n",
    "x_train[:, :40] /= np.sum(x_train[:, :40], axis=1).reshape(-1, 1)\n",
    "x_train[:, 42:47] /= np.sum(x_train[:, 42:47], axis=1).reshape(-1, 1)\n",
    "x_train[40] /= 100.\n",
    "\n",
    "x_test[:, :40] /= np.sum(x_test[:, :40], axis=1).reshape(-1, 1)\n",
    "x_test[:, 42:47] /= np.sum(x_test[:, 42:47], axis=1).reshape(-1, 1)\n",
    "x_test[40] /= 100.\n",
    "\n",
    "\n",
    "## Scaler\n",
    "scaler = MinMaxScaler()\n",
    "# Apply scaling only to fluxes\n",
    "scaler.fit(x_train[:, :47])\n",
    "x_train[:, :47] = scaler.transform(x_train[:, :47])\n",
    "x_test[:, :47] = scaler.transform(x_test[:, :47])\n",
    "\n",
    "# # PCA\n",
    "# pca = PCA(n_components=0.99, svd_solver='full')\n",
    "\n",
    "# pca.fit(x_train)\n",
    "# x_train = pca.transform(x_train)\n",
    "# x_test = pca.transform(x_test)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_grid_search(algorithm, search_mode='random'):\n",
    "    # Create the parameter grid based on the results of random search\n",
    "    if algorithm == 'nn':\n",
    "        param_grid = {\n",
    "            'hidden_layer_sizes': [(60, 60), (60, 60, 60),\n",
    "                                   (50, 50, 20), (40, 40, 20),\n",
    "                                   (40, 30, 15)],\n",
    "            'solver': ['adam'],\n",
    "            'alpha': [1e-2, 1e-3, 1e-4],\n",
    "            'batch_size': [50, 100, 250, 300],\n",
    "            'learning_rate': ['adaptive', 'constant'],\n",
    "            'max_iter': [10000]\n",
    "        }\n",
    "        # Create a based model\n",
    "        model = MLPClassifier()\n",
    "    elif algorithm == 'rf':\n",
    "        param_grid = {\n",
    "            'random_state': [22],\n",
    "            'n_estimators': [1000],\n",
    "            'bootstrap': [True, False],\n",
    "            'max_depth': [20, 50, 70, 100],\n",
    "            'min_samples_split': [2, 5, 10, 20],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "        model = RandomForestClassifier()\n",
    "    else:\n",
    "        raise Exception('Model not known')\n",
    "\n",
    "    # Instantiate the grid search model\n",
    "    if search_mode == 'grid':\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model, param_grid=param_grid,\n",
    "            cv=3, n_jobs=-1, pre_dispatch='2*n_jobs',\n",
    "            verbose=3,\n",
    "        )\n",
    "    elif search_mode == 'random':\n",
    "        grid_search = RandomizedSearchCV(\n",
    "            estimator=model, param_distributions=param_grid,\n",
    "            cv=3, n_jobs=-1, pre_dispatch='2*n_jobs',\n",
    "            verbose=3,\n",
    "        )\n",
    "    else:\n",
    "        raise Exception('What?')\n",
    "\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    return grid_search.best_params_\n",
    "\n",
    "model = 'nn'\n",
    "search_mode = 'grid'\n",
    "\n",
    "best_params = do_grid_search(model, search_mode=search_mode)\n",
    "# if model == 'nn':\n",
    "#     best_params = {'activation': 'relu',\n",
    "#     'alpha': 0.001,\n",
    "#     'batch_size': 50,\n",
    "#     'beta_1': 0.9,\n",
    "#     'beta_2': 0.999,\n",
    "#     'early_stopping': False,\n",
    "#     'epsilon': 1e-08,\n",
    "#     'hidden_layer_sizes': (60, 60, 60),\n",
    "#     'learning_rate': 'constant',\n",
    "#     'learning_rate_init': 0.001,\n",
    "#     'max_fun': 15000,\n",
    "#     'max_iter': 10000,\n",
    "#     'momentum': 0.9,\n",
    "#     'n_iter_no_change': 10,\n",
    "#     'nesterovs_momentum': True,\n",
    "#     'power_t': 0.5,\n",
    "#     'random_state': None,\n",
    "#     'shuffle': True,\n",
    "#     'solver': 'adam',\n",
    "#     'tol': 0.0001,\n",
    "#     'validation_fraction': 0.1,\n",
    "#     'verbose': False,\n",
    "#     'warm_start': False} \n",
    "# elif model == 'rf':\n",
    "#     best_params = {'random_state': 22, 'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 20, 'bootstrap': False, 'n_jobs': -1}\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == 'nn':\n",
    "    cl_best = MLPClassifier(**best_params)\n",
    "elif model == 'rf':\n",
    "    cl_best = RandomForestClassifier(**best_params, n_jobs=-1)\n",
    "\n",
    "cl_best.fit(x_train, y_train)\n",
    "test_score = cl_best.score(x_test, y_test)\n",
    "train_score = cl_best.score(x_train, y_train)\n",
    "print(f'Score\\n\\nTrain: {train_score:0.3f}\\nTest: {test_score:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test\n",
    "pred_test = cl_best.predict(x_test)\n",
    "log_p = cl_best.predict_log_proba(x_test)\n",
    "\n",
    "for src in range(len(pred_test)):\n",
    "    if pred_test[src] == 4:\n",
    "        pred_i = 2\n",
    "    elif pred_test[src] == 5:\n",
    "        pred_i = 3\n",
    "    else:\n",
    "        pred_i = pred_test[src] - 1\n",
    "    class_log_p = log_p[src, pred_i]\n",
    "    if class_log_p < np.log(0.00000001):\n",
    "        pred_test[src] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier\n",
    "save_dir = '/home/alberto/almacen/PAUS_data/ML_classifier'\n",
    "with open(f'{save_dir}/source_classifier.sav', 'wb') as file:\n",
    "    pickle.dump(cl_best, file)\n",
    "# with open(f'{save_dir}/source_pca.sav', 'wb') as file:\n",
    "#     pickle.dump(pca, file)\n",
    "with open(f'{save_dir}/source_scaler.sav', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmag_train, rmag_test =\\\n",
    "    model_selection.train_test_split(rmag, test_size=0.2, random_state=split_seed)\n",
    "zspec_train, zspec_test =\\\n",
    "    model_selection.train_test_split(zspec, test_size=0.2, random_state=split_seed)\n",
    "L_Arr_train, L_Arr_test =\\\n",
    "    model_selection.train_test_split(L_Arr, test_size=0.2, random_state=split_seed)\n",
    "zphot_train, zphot_test =\\\n",
    "    model_selection.train_test_split(zphot, test_size=0.2, random_state=split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "r_mask = (L_Arr_test >= 43.5) & (rmag_test < 23)\n",
    "cm = confusion_matrix(y_test[r_mask], pred_test[r_mask],\n",
    "                      labels=[1, 2, 4])\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = cm.astype('float') / cm.sum(axis=0)[np.newaxis, :]\n",
    "label_names_cm = ['QSO cont.', 'QSO LAE', r'Low-$z$ galaxy']\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='.2f',\n",
    "            xticklabels=label_names_cm, yticklabels=label_names_cm,\n",
    "            cbar=False, annot_kws={\"fontsize\":17})\n",
    "plt.xlabel('Predicted Labels', fontsize=17)\n",
    "plt.ylabel('True Labels', fontsize=17)\n",
    "plt.savefig('../figures/NN_class_confusion_matrix.pdf', bbox_inches='tight', pad_inches=0.1,\n",
    "            facecolor='w')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# r_mask = (rmag_test >= 23)\n",
    "# cm = confusion_matrix(y_test[r_mask], pred_test[r_mask])\n",
    "\n",
    "# # Plot confusion matrix\n",
    "# cm = cm.astype('float') / cm.sum(axis=0)[np.newaxis, :]\n",
    "# label_names_cm = ['QSO_cont', 'QSO_LAE', 'GAL', '?']\n",
    "# sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='.2f',\n",
    "#             xticklabels=label_names_cm, yticklabels=label_names_cm,\n",
    "#             cbar=False)\n",
    "# plt.xlabel(\"Predicted Labels\")\n",
    "# plt.ylabel(\"True Labels\")\n",
    "# plt.title('r $\\geq$ 22')\n",
    "# plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute confusion matrix\n",
    "# r_mask = (rmag_test > 22)\n",
    "# cm = confusion_matrix(y_test[r_mask], pred_test[r_mask])\n",
    "\n",
    "# # Plot confusion matrix\n",
    "# cm = cm.astype('float') / cm.sum(axis=0)[np.newaxis, :]\n",
    "# sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='.2f',\n",
    "#             xticklabels=label_names, yticklabels=label_names,\n",
    "#             cbar=False)\n",
    "# plt.xlabel(\"Predicted Labels\")\n",
    "# plt.ylabel(\"True Labels\")\n",
    "# plt.title('$r > 22$')\n",
    "# plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jpasLAEs.utils import bin_centers\n",
    "\n",
    "# extra_mask = (rmag_test < 24)\n",
    "# laes_as_laes = ((pred_test == 2) | (pred_test == 3)) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "# laes_as_cont = ((pred_test == 1) | (pred_test == 4)) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "# laes_as_gal = ((pred_test == 4)) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "# laes_as_badqso = (pred_test == 1) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "# badqso_as_badqso = (pred_test == 1) & (y_test == 1)\n",
    "# gal_as_cont = (y_test == 4) & ((pred_test == 4) | (pred_test == 1))\n",
    "# gal_as_lae = (y_test == 4) & ((pred_test == 2) | (pred_test == 3))\n",
    "\n",
    "# z_bins = np.linspace(2.7, 4, 15)\n",
    "# z_bins_c = bin_centers(z_bins)\n",
    "# h_good_laes, _ = np.histogram(zphot_test[laes_as_laes], z_bins)\n",
    "# h_bad_laes, _ = np.histogram(zphot_test[laes_as_cont], z_bins)\n",
    "# h_laes_as_gal, _ = np.histogram(zphot_test[laes_as_gal], z_bins)\n",
    "# h_laes_as_badqso, _ = np.histogram(zphot_test[laes_as_badqso], z_bins)\n",
    "# h_gal_as_cont, _ = np.histogram(zphot_test[gal_as_cont], z_bins)\n",
    "# h_gal_as_lae, _ = np.histogram(zphot_test[gal_as_lae], z_bins)\n",
    "# h_all_gal, _ = np.histogram(zphot_test[pred_test == 4], z_bins)\n",
    "# h_badqso_as_badqso, _ = np.histogram(zphot_test[badqso_as_badqso], z_bins)\n",
    "# h_all_badqso, _ = np.histogram(zphot_test[pred_test == 1], z_bins)\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "# ax.plot(z_bins_c, h_good_laes / (h_good_laes + h_bad_laes), label='LAEs as LAEs')\n",
    "# ax.plot(z_bins_c, h_laes_as_gal / (h_good_laes + h_bad_laes), label='LAEs as GAL')\n",
    "# ax.plot(z_bins_c, h_laes_as_badqso / (h_good_laes + h_bad_laes), label='LAEs as low-z QSO')\n",
    "# ax.plot(z_bins_c, h_gal_as_cont / h_all_gal, label='GAL as GAL')\n",
    "# ax.plot(z_bins_c, h_badqso_as_badqso / h_all_badqso, label='low-z QSO as low-z QSO')\n",
    "\n",
    "\n",
    "# ax.legend(fontsize=11)\n",
    "# ax.set_ylim(0, 1)\n",
    "\n",
    "# ax.set_xlabel('zphot')\n",
    "\n",
    "# plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra_mask = (rmag_test < 24)\n",
    "# laes_as_laes = ((pred_test == 2) | (pred_test == 3)) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "# laes_as_cont = ((pred_test == 1) | (pred_test == 4)) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "# laes_as_gal = ((pred_test == 4)) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "# laes_as_badqso = (pred_test == 1) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "# badqso_as_badqso = (pred_test == 1) & (y_test == 1)\n",
    "# gal_as_cont = (y_test == 4) & ((pred_test == 4) | (pred_test == 1))\n",
    "# gal_as_lae = (y_test == 4) & ((pred_test == 2) | (pred_test == 3))\n",
    "\n",
    "# L_lya_bins = np.linspace(42, 46, 15)\n",
    "# L_lya_bins_c = bin_centers(L_lya_bins)\n",
    "# h_good_laes, _ = np.histogram(L_Arr_test[laes_as_laes], L_lya_bins)\n",
    "# h_bad_laes, _ = np.histogram(L_Arr_test[laes_as_cont], L_lya_bins)\n",
    "# h_laes_as_gal, _ = np.histogram(L_Arr_test[laes_as_gal], L_lya_bins)\n",
    "# h_laes_as_badqso, _ = np.histogram(L_Arr_test[laes_as_badqso], L_lya_bins)\n",
    "# h_gal_as_cont, _ = np.histogram(L_Arr_test[gal_as_cont], L_lya_bins)\n",
    "# h_gal_as_lae, _ = np.histogram(L_Arr_test[gal_as_lae], L_lya_bins)\n",
    "# h_all_gal, _ = np.histogram(L_Arr_test[pred_test == 4], L_lya_bins)\n",
    "# h_badqso_as_badqso, _ = np.histogram(L_Arr_test[badqso_as_badqso], L_lya_bins)\n",
    "# h_all_badqso, _ = np.histogram(L_Arr_test[pred_test == 1], L_lya_bins)\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "# ax.plot(L_lya_bins_c, h_good_laes / (h_good_laes + h_bad_laes), label='LAEs as LAEs')\n",
    "# ax.plot(L_lya_bins_c, h_laes_as_gal / (h_good_laes + h_bad_laes), label='LAEs as GAL')\n",
    "# ax.plot(L_lya_bins_c, h_laes_as_badqso / (h_good_laes + h_bad_laes), label='LAEs as low-z QSO')\n",
    "# ax.plot(L_lya_bins_c, h_gal_as_cont / h_all_gal, label='GAL as GAL')\n",
    "# ax.plot(L_lya_bins_c, h_badqso_as_badqso / h_all_badqso, label='low-z QSO as low-z QSO')\n",
    "\n",
    "\n",
    "# ax.legend(fontsize=11)\n",
    "# ax.set_ylim(0, 1)\n",
    "\n",
    "# ax.set_xlabel('L_lya')\n",
    "\n",
    "# plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ROC curves\n",
    "# from sklearn.metrics import roc_curve\n",
    "\n",
    "# # TRUE MEANS CONTAMINANT HERE\n",
    "\n",
    "# y_binary = np.zeros_like(y_test).astype(bool)\n",
    "# y_binary[y_test != 2] = True\n",
    "\n",
    "# cont_p = 1 - np.exp(log_p[:, 1])\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(y_binary, cont_p)\n",
    "\n",
    "# # Compute nice threshold\n",
    "# fpr_thresh_Arr = np.array([0.1, 0.05, 0.01])\n",
    "# thresh_Arr = np.empty_like(fpr_thresh_Arr)\n",
    "# for i, this_fpr in enumerate(fpr_thresh_Arr):\n",
    "#     thresh_Arr[i] = thresholds[fpr >= this_fpr][0]\n",
    "\n",
    "# print(thresh_Arr)\n",
    "\n",
    "# # Represent the ROC curve\n",
    "# fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "# ax.plot(fpr, tpr, lw=2)\n",
    "# for thr in thresh_Arr:\n",
    "#     # ax.axvline(fpr[thresholds == thr], ls='--', c='k')\n",
    "#     ax.axvline(fpr[thresholds == thr], ls='--', c='k')\n",
    "\n",
    "# ax.set_xlabel('FALSE POSITIVE RATE')\n",
    "# ax.set_ylabel('TRUE POSITIVE RATE')\n",
    "# ax.set_ylim(0, 1)\n",
    "# ax.set_xlim(0, 1)\n",
    "\n",
    "# plt.show(block=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
