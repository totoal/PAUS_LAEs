{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from paus_utils import w_central, z_NB\n",
    "\n",
    "from jpasLAEs.utils import flux_to_mag, bin_centers\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from load_paus_mocks import load_mock_dict\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'W3'\n",
    "savedir = '/home/alberto/almacen/PAUS_data/LF_corrections'\n",
    "\n",
    "nb_min, nb_max = 0, 16\n",
    "\n",
    "with open(f'{savedir}/mock_dict_{field_name}_nb{nb_min}-{nb_max}.pkl', 'rb') as f:\n",
    "    mock_dict = pickle.load(f)\n",
    "\n",
    "# del mock_dict['SFG']\n",
    "\n",
    "mock_dict['GAL'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the minimum number of candidates to set the set length\n",
    "N_candidates_list = []\n",
    "for mock_name, mock in mock_dict.items():\n",
    "    N_candidates_list.append(sum(mock['nice_lya_0']))\n",
    "\n",
    "set_len = np.min(N_candidates_list)\n",
    "print(N_candidates_list)\n",
    "print(f'{set_len=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the set for each class\n",
    "tt_set = None\n",
    "labels = None\n",
    "rmag = None\n",
    "zspec = None\n",
    "zphot = None\n",
    "L_Arr = None\n",
    "\n",
    "for mock_name, mock in mock_dict.items():\n",
    "    mock_len = len(mock['zspec'])\n",
    "    nice_lya = mock['nice_lya_0']\n",
    "    np.random.seed(299792458)\n",
    "    selection = np.random.choice(np.arange(mock_len)[nice_lya], set_len,\n",
    "                                 replace=False)\n",
    "    this_set = np.hstack([\n",
    "        mock['flx'][:40, selection].T * 1e17, # NBs\n",
    "        mock['lya_NB'][selection].reshape(-1, 1),\n",
    "        mock['r_mag'][selection].reshape(-1, 1),\n",
    "        mock['flx'][41:45, selection].T * 1e17, # BBs\n",
    "    ])\n",
    "\n",
    "    if tt_set is None:\n",
    "        tt_set = this_set\n",
    "        this_rmag = flux_to_mag(mock['flx'][-4, selection], w_central[-4])\n",
    "        rmag = this_rmag\n",
    "        zspec = mock['zspec'][selection]\n",
    "        L_Arr = mock['L_lya'][selection]\n",
    "        zphot = z_NB(mock['lya_NB'])[selection]\n",
    "    else:\n",
    "        tt_set = np.vstack([tt_set, this_set])\n",
    "\n",
    "        this_rmag = flux_to_mag(mock['flx'][-4, selection], w_central[-4])\n",
    "        rmag = np.concatenate([rmag, this_rmag])\n",
    "        zspec = np.concatenate([zspec, mock['zspec'][selection]])\n",
    "        L_Arr = np.concatenate([L_Arr, mock['L_lya'][selection]])\n",
    "        zphot = np.concatenate([zphot, z_NB(mock['lya_NB'])[selection]])\n",
    "    \n",
    "\n",
    "label_names = []\n",
    "for i in range(len(mock_dict)):\n",
    "    mock_name = list(mock_dict.keys())[i]\n",
    "    print(f'{i} for {mock_name}')\n",
    "    if labels is None:\n",
    "        labels = np.ones(set_len).astype(int) * i\n",
    "    else:\n",
    "        labels = np.concatenate([labels, np.ones(set_len).astype(int) * i])\n",
    "    label_names.append(mock_name)\n",
    "label_names.append('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "split_seed = 299792458\n",
    "x_train, x_test, y_train, y_test =\\\n",
    "    model_selection.train_test_split(tt_set, labels, test_size=0.2,\n",
    "                                     random_state=split_seed)\n",
    "\n",
    "## Pre-processing ##\n",
    "\n",
    "x_train[:, :40] /= np.sum(x_train[:, :40], axis=1).reshape(-1, 1)\n",
    "x_train[:, 41:45] /= np.sum(x_train[:, 41:45], axis=1).reshape(-1, 1)\n",
    "x_train[:, 40] /= 16.\n",
    "x_train[:, 41] /= 24.\n",
    "\n",
    "x_test[:, :40] /= np.sum(x_test[:, :40], axis=1).reshape(-1, 1)\n",
    "x_test[:, 41:45] /= np.sum(x_test[:, 41:45], axis=1).reshape(-1, 1)\n",
    "x_test[:, 40] /= 16.\n",
    "x_test[:, 41] /= 24.\n",
    "\n",
    "# Standard scaler\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(x_train)\n",
    "# x_train = scaler.transform(x_train)\n",
    "# x_test = scaler.transform(x_test)\n",
    "\n",
    "# PCA\n",
    "# pca = PCA(n_components=0.999999, svd_solver='full')\n",
    "\n",
    "# pca.fit(x_train)\n",
    "# x_train = pca.transform(x_train)\n",
    "# x_test = pca.transform(x_test)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_grid_search(algorithm, search_mode='random'):\n",
    "    # Create the parameter grid based on the results of random search\n",
    "    if algorithm == 'nn':\n",
    "        param_grid = {\n",
    "            'hidden_layer_sizes': [(60, 60), (60, 60, 60), (60, 40), (50, 50),\n",
    "                                   (50, 50, 20), (40, 20),],\n",
    "            'solver': ['adam'],\n",
    "            'alpha': [1e-3, 1e-4, 1e-5],\n",
    "            'batch_size': [250, 300, 500, 'auto'],\n",
    "            'learning_rate': ['adaptive', 'constant'],\n",
    "        }\n",
    "        # Create a based model\n",
    "        model = MLPClassifier()\n",
    "    elif algorithm == 'rf':\n",
    "        param_grid = {\n",
    "            'random_state': [22],\n",
    "            'n_estimators': [50, 100, 300, 500, 1000],\n",
    "            'bootstrap': [True, False],\n",
    "            'max_depth': [20, 50, 70, 100],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "        model = RandomForestClassifier()\n",
    "    else:\n",
    "        raise Exception('Model not known')\n",
    "\n",
    "    # Instantiate the grid search model\n",
    "    if search_mode == 'grid':\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model, param_grid=param_grid,\n",
    "            cv=3, n_jobs=-1, pre_dispatch='2*n_jobs',\n",
    "            verbose=3,\n",
    "        )\n",
    "    elif search_mode == 'random':\n",
    "        grid_search = RandomizedSearchCV(\n",
    "            estimator=model, param_distributions=param_grid,\n",
    "            cv=3, n_jobs=-1, pre_dispatch='2*n_jobs',\n",
    "            verbose=3,\n",
    "        )\n",
    "    else:\n",
    "        raise Exception('What?')\n",
    "\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    return grid_search.best_params_\n",
    "\n",
    "model = 'nn'\n",
    "search_mode = 'random'\n",
    "# best_params = do_grid_search(model, search_mode=search_mode)\n",
    "if model == 'nn':\n",
    "    best_params = {'alpha': 0.0001, 'batch_size': 300, 'hidden_layer_sizes': (60, 60), 'learning_rate': 'adaptive', 'max_iter': 10000, 'shuffle': False, 'solver': 'adam'} \n",
    "elif model == 'rf':\n",
    "    best_params = {'random_state': 22, 'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 20, 'bootstrap': False}\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == 'nn':\n",
    "    cl_best = MLPClassifier(**best_params)\n",
    "elif model == 'rf':\n",
    "    cl_best = RandomForestClassifier(**best_params)\n",
    "\n",
    "cl_best.fit(x_train, y_train)\n",
    "test_score = cl_best.score(x_test, y_test)\n",
    "train_score = cl_best.score(x_train, y_train)\n",
    "print(f'Score\\n\\nTrain: {train_score:0.3f}\\nTest: {test_score:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test\n",
    "pred_test = cl_best.predict(x_test)\n",
    "log_p = cl_best.predict_log_proba(x_test)\n",
    "\n",
    "class_log_p = log_p[np.arange(len(log_p)), pred_test]\n",
    "log_p_mask = (class_log_p > np.log(0.9))\n",
    "\n",
    "pred_test[log_p_mask] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Save the classifier\n",
    "# save_dir = '/home/alberto/almacen/PAUS_data/ML_classifier'\n",
    "# with open(f'{save_dir}/source_classifier.sav', 'wb') as file:\n",
    "#     pickle.dump(cl_best, file)\n",
    "# with open(f'{save_dir}/source_pca.sav', 'wb') as file:\n",
    "#     pickle.dump(pca, file)\n",
    "# with open(f'{save_dir}/source_scaler.sav', 'wb') as file:\n",
    "    # pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmag_train, rmag_test =\\\n",
    "    model_selection.train_test_split(rmag, test_size=0.2, random_state=split_seed)\n",
    "zspec_train, zspec_test =\\\n",
    "    model_selection.train_test_split(zspec, test_size=0.2, random_state=split_seed)\n",
    "L_Arr_train, L_Arr_test =\\\n",
    "    model_selection.train_test_split(L_Arr, test_size=0.2, random_state=split_seed)\n",
    "zphot_train, zphot_test =\\\n",
    "    model_selection.train_test_split(zphot, test_size=0.2, random_state=split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "r_mask = (rmag_test < 22)\n",
    "cm = confusion_matrix(y_test[r_mask], pred_test[r_mask])\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = cm.astype('float') / cm.sum(axis=0)[np.newaxis, :]\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='.2f',\n",
    "            xticklabels=label_names, yticklabels=label_names,\n",
    "            cbar=False)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title('$r < 22$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "r_mask = (rmag_test > 22)\n",
    "cm = confusion_matrix(y_test[r_mask], pred_test[r_mask])\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = cm.astype('float') / cm.sum(axis=0)[np.newaxis, :]\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='.2f',\n",
    "            xticklabels=label_names, yticklabels=label_names,\n",
    "            cbar=False)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title('$r > 22$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "r_mask = (rmag_test >= 2)\n",
    "cm = confusion_matrix(y_test[r_mask], pred_test[r_mask])\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = cm.astype('float') / cm.sum(axis=0)[np.newaxis, :]\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='.2f',\n",
    "            xticklabels=label_names, yticklabels=label_names,\n",
    "            cbar=False)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title('r $\\geq$ 0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jpasLAEs.utils import bin_centers\n",
    "\n",
    "extra_mask = (rmag_test < 24)\n",
    "laes_as_laes = ((pred_test == 2) | (pred_test == 3)) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "laes_as_cont = ((pred_test == 1) | (pred_test == 4)) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "laes_as_gal = ((pred_test == 4)) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "laes_as_badqso = (pred_test == 1) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "badqso_as_badqso = (pred_test == 1) & (y_test == 1)\n",
    "gal_as_cont = (y_test == 4) & ((pred_test == 4) | (pred_test == 1))\n",
    "gal_as_lae = (y_test == 4) & ((pred_test == 2) | (pred_test == 3))\n",
    "\n",
    "z_bins = np.linspace(2.7, 4, 15)\n",
    "z_bins_c = bin_centers(z_bins)\n",
    "h_good_laes, _ = np.histogram(zphot_test[laes_as_laes], z_bins)\n",
    "h_bad_laes, _ = np.histogram(zphot_test[laes_as_cont], z_bins)\n",
    "h_laes_as_gal, _ = np.histogram(zphot_test[laes_as_gal], z_bins)\n",
    "h_laes_as_badqso, _ = np.histogram(zphot_test[laes_as_badqso], z_bins)\n",
    "h_gal_as_cont, _ = np.histogram(zphot_test[gal_as_cont], z_bins)\n",
    "h_gal_as_lae, _ = np.histogram(zphot_test[gal_as_lae], z_bins)\n",
    "h_all_gal, _ = np.histogram(zphot_test[pred_test == 4], z_bins)\n",
    "h_badqso_as_badqso, _ = np.histogram(zphot_test[badqso_as_badqso], z_bins)\n",
    "h_all_badqso, _ = np.histogram(zphot_test[pred_test == 1], z_bins)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.plot(z_bins_c, h_good_laes / (h_good_laes + h_bad_laes), label='LAEs as LAEs')\n",
    "ax.plot(z_bins_c, h_laes_as_gal / (h_good_laes + h_bad_laes), label='LAEs as GAL')\n",
    "ax.plot(z_bins_c, h_laes_as_badqso / (h_good_laes + h_bad_laes), label='LAEs as low-z QSO')\n",
    "ax.plot(z_bins_c, h_gal_as_cont / h_all_gal, label='GAL as GAL')\n",
    "ax.plot(z_bins_c, h_badqso_as_badqso / h_all_badqso, label='low-z QSO as low-z QSO')\n",
    "\n",
    "\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel('zphot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_mask = (rmag_test < 24)\n",
    "laes_as_laes = ((pred_test == 2) | (pred_test == 3)) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "laes_as_cont = ((pred_test == 1) | (pred_test == 4)) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "laes_as_gal = ((pred_test == 4)) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "laes_as_badqso = (pred_test == 1) & ((y_test == 2) | (y_test == 3)) & extra_mask\n",
    "badqso_as_badqso = (pred_test == 1) & (y_test == 1)\n",
    "gal_as_cont = (y_test == 4) & ((pred_test == 4) | (pred_test == 1))\n",
    "gal_as_lae = (y_test == 4) & ((pred_test == 2) | (pred_test == 3))\n",
    "\n",
    "L_lya_bins = np.linspace(42, 46, 15)\n",
    "L_lya_bins_c = bin_centers(L_lya_bins)\n",
    "h_good_laes, _ = np.histogram(L_Arr_test[laes_as_laes], L_lya_bins)\n",
    "h_bad_laes, _ = np.histogram(L_Arr_test[laes_as_cont], L_lya_bins)\n",
    "h_laes_as_gal, _ = np.histogram(L_Arr_test[laes_as_gal], L_lya_bins)\n",
    "h_laes_as_badqso, _ = np.histogram(L_Arr_test[laes_as_badqso], L_lya_bins)\n",
    "h_gal_as_cont, _ = np.histogram(L_Arr_test[gal_as_cont], L_lya_bins)\n",
    "h_gal_as_lae, _ = np.histogram(L_Arr_test[gal_as_lae], L_lya_bins)\n",
    "h_all_gal, _ = np.histogram(L_Arr_test[pred_test == 4], L_lya_bins)\n",
    "h_badqso_as_badqso, _ = np.histogram(L_Arr_test[badqso_as_badqso], L_lya_bins)\n",
    "h_all_badqso, _ = np.histogram(L_Arr_test[pred_test == 1], L_lya_bins)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.plot(L_lya_bins_c, h_good_laes / (h_good_laes + h_bad_laes), label='LAEs as LAEs')\n",
    "ax.plot(L_lya_bins_c, h_laes_as_gal / (h_good_laes + h_bad_laes), label='LAEs as GAL')\n",
    "ax.plot(L_lya_bins_c, h_laes_as_badqso / (h_good_laes + h_bad_laes), label='LAEs as low-z QSO')\n",
    "ax.plot(L_lya_bins_c, h_gal_as_cont / h_all_gal, label='GAL as GAL')\n",
    "ax.plot(L_lya_bins_c, h_badqso_as_badqso / h_all_badqso, label='low-z QSO as low-z QSO')\n",
    "\n",
    "\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel('L_lya')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
