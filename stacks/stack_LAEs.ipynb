{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "# matplotlib.rc('text', usetex=True)\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "import astropy.units as u\n",
    "\n",
    "from load_paus_cat import load_paus_cat\n",
    "from paus_utils import w_central, z_NB\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_cat = fits.open('/home/alberto/almacen/PAUS_data/catalogs/PAUS_LAE_selection_visual_insp_AT.fits')[1].data\n",
    "vi_cat_hiz = fits.open('/home/alberto/almacen/PAUS_data/catalogs/LAE_selection_VI_hiZ.fits')[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paus_tcurves_dir = '/home/alberto/almacen/PAUS_data/OUT_FILTERS'\n",
    "tcurves_file_list = os.listdir(paus_tcurves_dir)\n",
    "tcurves_file_list.sort()\n",
    "\n",
    "paus_fil_names = []\n",
    "\n",
    "for name in tcurves_file_list:\n",
    "    if name[4] == 'D':\n",
    "        this_name = f'NB{name[6:9]}'\n",
    "    else:\n",
    "        this_name = name[-5]\n",
    "\n",
    "    paus_fil_names.append(this_name)\n",
    "\n",
    "paus_fil_names = paus_fil_names[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize output data dict\n",
    "to_stack_data = {}\n",
    "for nbi in range(40):\n",
    "    to_stack_data[paus_fil_names[nbi]] = []\n",
    "    to_stack_data[f'{paus_fil_names[nbi]}_error'] = []\n",
    "to_stack_data['z'] = []\n",
    "to_stack_lya_NB = []\n",
    "to_stack_L_lya = []\n",
    "\n",
    "\n",
    "for field_name in ['W1', 'W2', 'W3']:\n",
    "    path_to_cat = [f'/home/alberto/almacen/PAUS_data/catalogs/PAUS_3arcsec_{field_name}_extinction_corrected.pq']\n",
    "    cat = load_paus_cat(path_to_cat)\n",
    "\n",
    "    # Get IDs from LAEs visually selected\n",
    "    # mask = ~vi_cat['is_junk_VI'] & (vi_cat['field'] == field_name)\n",
    "    mask = vi_cat['is_LAE_VI'] & (vi_cat['field'] == field_name)\n",
    "    # mask = vi_cat['is_hiZ_LAE'] & (vi_cat['field'] == field_name)\n",
    "\n",
    "\n",
    "    LAE_vi_IDs = np.array(vi_cat['ref_id'][mask])\n",
    "\n",
    "    lya_NB = np.array(vi_cat['lya_NB'][mask])\n",
    "\n",
    "    redshifts  = np.array(vi_cat['z_NB'][mask])\n",
    "    # redshifts = z_NB(lya_NB)\n",
    "    L_lya  = np.array(vi_cat['L_lya_corr'][mask])\n",
    "    print(len(LAE_vi_IDs))\n",
    "\n",
    "    where_LAEs_in_cat = np.empty_like(LAE_vi_IDs).astype(int)\n",
    "    for i, thisid in enumerate(LAE_vi_IDs):\n",
    "        where_LAEs_in_cat[i] = np.where(thisid == cat['ref_id'])[0][0]\n",
    "\n",
    "    # Compute normalization for each source, in the 160-180 nm band (rest-frame)\n",
    "    norm = np.empty_like(L_lya)\n",
    "    norm_wl_min, norm_wl_max = 1300, 1365\n",
    "\n",
    "    for src in range(len(L_lya)):\n",
    "        mask_norm_band = (w_central > norm_wl_min * (1 + redshifts[src])) & (w_central < norm_wl_max * (1 + redshifts[src]))\n",
    "        mask_norm_band[-6:] = False\n",
    "        dl = cosmo.luminosity_distance(redshifts[src]).to(u.cm).value\n",
    "        norm[src] = np.average(cat['flx'][mask_norm_band, where_LAEs_in_cat[src]] * 1450 * (1 + redshifts[src]) * dl**2,\n",
    "                               weights=(cat['err'][mask_norm_band, where_LAEs_in_cat[src]] * 1450 * (1 + redshifts[src]) * dl**2)**-2)\n",
    "\n",
    "    # Data to save to a .csv to be read by stonp\n",
    "    # 40 Narrow-bands\n",
    "    for nbi in range(40):\n",
    "        to_stack_data[paus_fil_names[nbi]].append(cat['flx'][nbi, where_LAEs_in_cat] / norm)\n",
    "        to_stack_data[f'{paus_fil_names[nbi]}_error'].append(cat['err'][nbi, where_LAEs_in_cat] / norm)\n",
    "    to_stack_data['z'].append(redshifts)\n",
    "    to_stack_lya_NB.append(lya_NB)\n",
    "    to_stack_L_lya.append(L_lya)\n",
    "\n",
    "for field_name in ['W1', 'W2', 'W3']:\n",
    "    path_to_cat = [f'/home/alberto/almacen/PAUS_data/catalogs/PAUS_3arcsec_{field_name}_extinction_corrected.pq']\n",
    "    cat = load_paus_cat(path_to_cat)\n",
    "\n",
    "    # Get IDs from LAEs visually selected\n",
    "    mask = vi_cat_hiz['is_hiZ_LAE'] & (vi_cat_hiz['field'] == field_name)\n",
    "\n",
    "\n",
    "    LAE_vi_IDs = np.array(vi_cat_hiz['ref_id'][mask])\n",
    "\n",
    "    lya_NB = np.array(vi_cat_hiz['lya_NB'][mask])\n",
    "    lya_NB[vi_cat_hiz['lya_NB_VI'][mask] > 0] = vi_cat_hiz['lya_NB_VI'][mask][vi_cat_hiz['lya_NB_VI'][mask] > 0]\n",
    "\n",
    "\n",
    "    redshifts = z_NB(lya_NB)\n",
    "    L_lya  = np.array(vi_cat_hiz['L_lya_corr'][mask])\n",
    "    print(len(LAE_vi_IDs))\n",
    "\n",
    "    where_LAEs_in_cat = np.empty_like(LAE_vi_IDs).astype(int)\n",
    "    for i, thisid in enumerate(LAE_vi_IDs):\n",
    "        where_LAEs_in_cat[i] = np.where(thisid == cat['ref_id'])[0][0]\n",
    "\n",
    "    # Compute normalization for each source, in the 160-180 nm band (rest-frame)\n",
    "    norm = np.empty_like(L_lya)\n",
    "    norm_wl_min, norm_wl_max = 1300, 1365\n",
    "\n",
    "    for src in range(len(L_lya)):\n",
    "        mask_norm_band = (w_central > norm_wl_min * (1 + redshifts[src])) & (w_central < norm_wl_max * (1 + redshifts[src]))\n",
    "        mask_norm_band[-6:] = False\n",
    "        dl = cosmo.luminosity_distance(redshifts[src]).to(u.cm).value\n",
    "        norm[src] = np.average(cat['flx'][mask_norm_band, where_LAEs_in_cat[src]] * 1450 * (1 + redshifts[src]) * dl**2,\n",
    "                               weights=(cat['err'][mask_norm_band, where_LAEs_in_cat[src]] * 1450 * (1 + redshifts[src]) * dl**2)**-2)\n",
    "\n",
    "    # Data to save to a .csv to be read by stonp\n",
    "    # 40 Narrow-bands\n",
    "    for nbi in range(40):\n",
    "        to_stack_data[paus_fil_names[nbi]].append(cat['flx'][nbi, where_LAEs_in_cat] / norm)\n",
    "        to_stack_data[f'{paus_fil_names[nbi]}_error'].append(cat['err'][nbi, where_LAEs_in_cat] / norm)\n",
    "    to_stack_data['z'].append(redshifts)\n",
    "    to_stack_lya_NB.append(lya_NB)\n",
    "    to_stack_L_lya.append(L_lya)\n",
    "\n",
    "\n",
    "for nbi in range(40):\n",
    "    to_stack_data[paus_fil_names[nbi]] = np.concatenate(to_stack_data[paus_fil_names[nbi]])\n",
    "    to_stack_data[f'{paus_fil_names[nbi]}_error'] = np.concatenate(to_stack_data[f'{paus_fil_names[nbi]}_error'])\n",
    "to_stack_data['z'] = np.concatenate(to_stack_data['z'])\n",
    "to_stack_lya_NB = np.concatenate(to_stack_lya_NB)\n",
    "to_stack_L_lya = np.concatenate(to_stack_L_lya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stonp\n",
    "\n",
    "# Save it to csv\n",
    "nb_list = [[0, 4], [3, 7], [6, 10], [9, 13], [12, 16], [14, 19], [19, 25], [23, 50]]\n",
    "# nb_list = [[3, 18]]\n",
    "\n",
    "\n",
    "wl_list = []\n",
    "stacked_seds_50 = []\n",
    "stacked_seds_16 = []\n",
    "stacked_seds_84 = []\n",
    "stacked_seds_err = []\n",
    "\n",
    "common_wl_grid = np.linspace(70, 250, 500)\n",
    "\n",
    "N_boots = 100\n",
    "for [nb1, nb2] in nb_list:\n",
    "    this_mask = (to_stack_lya_NB >= nb1) & (to_stack_lya_NB <= nb2) & (to_stack_L_lya > 43.5)\n",
    "    print(sum(this_mask))\n",
    "\n",
    "    this_df = pd.DataFrame(to_stack_data)[this_mask]\n",
    "    this_stack_50_list = []\n",
    "    for boot_i in range(N_boots):\n",
    "    # Bootstrap sources, save them as csv and stack\n",
    "        boot_ids = np.random.choice(np.arange(len(this_df)), len(this_df), replace=True)\n",
    "\n",
    "        df_to_save = this_df.iloc[boot_ids]\n",
    "        df_to_save.reset_index()\n",
    "\n",
    "        df_to_save.to_csv(f'fluxes_to_stack_NB{nb1}_{nb2}.csv')\n",
    "\n",
    "\n",
    "        st = stonp.Stacker()\n",
    "\n",
    "        st.load_catalog(f'fluxes_to_stack_NB{nb1}_{nb2}.csv', z_label='z')\n",
    "        # st.flux_units = u.dimensionless_unscaled\n",
    "        st.to_rest_frame(flux_conversion='luminosity', wl_obs_min=440, wl_obs_max=850)\n",
    "        st.stack(error_type='flux_error')\n",
    "        stack_50 = st.stacked_seds\n",
    "        stack_err = st.stack_sed_err\n",
    "\n",
    "        this_stack_50_list.append(np.interp(common_wl_grid, st.wl_grid, stack_50[0]))\n",
    "\n",
    "\n",
    "    wl_list.append(common_wl_grid)\n",
    "    stacked_seds_50.append(np.nanmean(this_stack_50_list, axis=0))\n",
    "    stacked_seds_16.append(np.nanpercentile(this_stack_50_list, axis=0, q=16))\n",
    "    stacked_seds_84.append(np.nanpercentile(this_stack_50_list, axis=0, q=84))\n",
    "    stacked_seds_err.append(np.nanstd(this_stack_50_list, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All\n",
    "this_mask = (to_stack_lya_NB >= 0) & (to_stack_lya_NB <= 30) & (to_stack_L_lya > 44)\n",
    "print(sum(this_mask))\n",
    "\n",
    "this_df = pd.DataFrame(to_stack_data)[this_mask]\n",
    "this_stack_50_list = []\n",
    "for boot_i in range(N_boots):\n",
    "# Bootstrap sources, save them as csv and stack\n",
    "    boot_ids = np.random.choice(np.arange(len(this_df)), len(this_df), replace=True)\n",
    "\n",
    "    df_to_save = this_df.iloc[boot_ids]\n",
    "    df_to_save.reset_index()\n",
    "\n",
    "    df_to_save.to_csv(f'fluxes_to_stack_NB{nb1}_{nb2}.csv')\n",
    "\n",
    "\n",
    "    st = stonp.Stacker()\n",
    "\n",
    "    st.load_catalog(f'fluxes_to_stack_NB{nb1}_{nb2}.csv', z_label='z')\n",
    "    st.to_rest_frame(flux_conversion='luminosity', wl_obs_min=440, wl_obs_max=850)\n",
    "    st.stack(error_type='flux_error')\n",
    "    stack_50 = st.stacked_seds\n",
    "    stack_err = st.stack_sed_err\n",
    "\n",
    "    this_stack_50_list.append(np.interp(common_wl_grid, st.wl_grid, stack_50[0]))\n",
    "\n",
    "sed_50_all = np.nanmean(this_stack_50_list, axis=0)\n",
    "sed_err_all = (np.nanpercentile(this_stack_50_list, axis=0, q=84) - np.nanpercentile(this_stack_50_list, axis=0, q=16)) * 0.5\n",
    "wl_all = common_wl_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainties import ufloat\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def QSO_cont(x, a, b):\n",
    "    return b * x**a\n",
    "\n",
    "z_list = []\n",
    "z_50 = []\n",
    "z_16 = []\n",
    "z_84 = []\n",
    "meas_flux_list = []\n",
    "meas_flux_16_list = []\n",
    "meas_flux_84_list = []\n",
    "pred_flux_list = []\n",
    "\n",
    "iii = 0\n",
    "for wl, sed_50, sed_16, sed_84 in zip(wl_list, stacked_seds_50, stacked_seds_16, stacked_seds_84):\n",
    "    this_mask = (to_stack_lya_NB >= nb_list[iii][0]) & (to_stack_lya_NB <= nb_list[iii][1])\n",
    "    this_z_mean = np.mean(to_stack_data['z'][this_mask])\n",
    "    wl_mask_fit = ((\n",
    "                    ((wl > 135) & (wl < 136.4))\n",
    "                    | ((wl > 145) & (wl < 148))\n",
    "                    # | ((wl > 177) & (wl < 182))\n",
    "                    # | ((wl > 200)) & (wl < 225)\n",
    "                    )\n",
    "                    & np.isfinite(sed_50))\n",
    "\n",
    "    try:\n",
    "        popt, pcov = curve_fit(QSO_cont, wl[wl_mask_fit], sed_50[wl_mask_fit],)\n",
    "                            #    sigma=sed_err[wl_mask_fit])\n",
    "    except:\n",
    "        print('Fit err')\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "    ax.errorbar(wl[wl_mask_fit], sed_50[wl_mask_fit], fmt='o')\n",
    "    ax.plot(wl, sed_50)\n",
    "\n",
    "    xx = np.linspace(100, 215, 1000)\n",
    "    ax.plot(xx, QSO_cont(xx, popt[0], popt[1]))\n",
    "\n",
    "\n",
    "    mask_lyforest = (wl > 113) & (wl < 115)\n",
    "    ax.plot(wl[mask_lyforest], sed_50[mask_lyforest], marker='o')\n",
    "\n",
    "    ax.axhline(0, c='k')\n",
    "    # ax.set_yscale('log')\n",
    "    # ax.set_ylim(1e-3)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    pred_flux = QSO_cont(113.5, ufloat(popt[0], pcov[0, 0]**0.5), ufloat(popt[1], pcov[1, 1]**0.5))\n",
    "    meas_flux = np.nanmean(sed_50[mask_lyforest])\n",
    "    meas_flux_16 = np.nanmean(sed_16[mask_lyforest])\n",
    "    meas_flux_84 = np.nanmean(sed_84[mask_lyforest])\n",
    "    # meas_flux_16 = np.nanpercentile(sed_50[mask_lyforest], q=16)\n",
    "    # meas_flux_84 = np.nanpercentile(sed_50[mask_lyforest], q=84)\n",
    "\n",
    "    LyF_trans = ufloat(meas_flux, (meas_flux_84 - meas_flux_16) * 0.5) / pred_flux\n",
    "    print(LyF_trans)\n",
    "\n",
    "    z_list.append(this_z_mean)\n",
    "    z_50.append(np.median(to_stack_data['z'][this_mask]))\n",
    "    z_16.append(np.percentile(to_stack_data['z'][this_mask], q=16))\n",
    "    z_84.append(np.percentile(to_stack_data['z'][this_mask], q=84))\n",
    "\n",
    "    meas_flux_list.append(meas_flux)\n",
    "    meas_flux_16_list.append(meas_flux_16)\n",
    "    meas_flux_84_list.append(meas_flux_84)\n",
    "    pred_flux_list.append(pred_flux)\n",
    "\n",
    "    iii += 1\n",
    "\n",
    "z_50 = np.array(z_50)\n",
    "z_16 = np.array(z_16)\n",
    "z_84 = np.array(z_84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmfit\n",
    "\n",
    "# sed_50 = stacked_seds_50[0]\n",
    "# sed_err = stacked_seds_err[0]\n",
    "# wl = wl_list[0]\n",
    "sed_50 = np.array(sed_50_all)\n",
    "sed_err = np.array(sed_err_all)\n",
    "wl = wl_all\n",
    "\n",
    "this_z_mean = np.mean(to_stack_data['z'])\n",
    "wl_mask_fit = ((\n",
    "                ((wl > 134) & (wl < 135))\n",
    "                | ((wl > 146) & (wl < 147))\n",
    "                # | ((wl > 169) & (wl < 170))\n",
    "                # | ((wl > 200)) & (wl < 225)\n",
    "                )\n",
    "                & np.isfinite(sed_50) & np.isfinite(sed_err))\n",
    "\n",
    "\n",
    "def QSO_cont_fit(x, a, b):\n",
    "    return np.log10(b * x**a)\n",
    "\n",
    "model = lmfit.Model(QSO_cont_fit)\n",
    "model.set_param_hint('a', value=-1.3, min=-4, max=0)\n",
    "model.set_param_hint('b', value=8, min=0, max=500)\n",
    "\n",
    "sed_to_fit = list(sed_50[wl_mask_fit]) * 100\n",
    "wl_to_fit = list(wl[wl_mask_fit]) * 100\n",
    "err_to_fit = list(sed_err[wl_mask_fit]) * 100\n",
    "sed_to_fit += np.random.normal(size=len(sed_to_fit)) * np.array(err_to_fit)\n",
    "\n",
    "result = model.fit(np.log10(sed_to_fit), x=wl_to_fit,\n",
    "                   weights=(np.array(err_to_fit))**-2,\n",
    "                   method='leastsq', nan_policy='propagate')\n",
    "print(result.fit_report())\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "norm = np.nanmax(sed_50)\n",
    "\n",
    "# ax.errorbar(wl[wl_mask_fit], sed_50[wl_mask_fit] / norm,\n",
    "#             fmt='o', yerr=sed_err[wl_mask_fit])\n",
    "ax.plot(wl, sed_50 / norm,\n",
    "        lw=2, c='teal')\n",
    "\n",
    "xx = np.linspace(92, 300, 1000)\n",
    "ax.plot(xx, QSO_cont(xx, result.params['a'], result.params['b']) / norm,\n",
    "        lw=2, zorder=-2314098, alpha=1, c='r', ls='--')\n",
    "\n",
    "\n",
    "# ax.fill_between([113, 115], [-1, -1], [100, 100],\n",
    "#                 color='orange', alpha=0.6, zorder=-99, lw=0)\n",
    "\n",
    "ax.fill_between([134, 135], [-1, -1], [100, 100],\n",
    "                color='dimgray', alpha=0.6, zorder=-99, lw=0)\n",
    "ax.fill_between([146, 147], [-1, -1], [100, 100],\n",
    "                color='dimgray', alpha=0.6, zorder=-99, lw=0)\n",
    "\n",
    "ax.text(92, 0.13, r'LyC', fontsize=12)\n",
    "ax.text(103.1, 0.45, r'Ly$\\beta$' + '\\n+OVI', fontsize=12)\n",
    "ax.text(122.1, 1, r'Ly$\\alpha$' + '\\n+NV', fontsize=12)\n",
    "ax.text(135, 0.35, 'SiIV\\n+OIV', fontsize=12)\n",
    "ax.text(156, 0.55, 'CIV', fontsize=12)\n",
    "ax.text(192, 0.3, 'CIII', fontsize=12)\n",
    "\n",
    "\n",
    "ax.axvline(91.2, ls=':', c='dimgray', zorder=-99)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "# ax.set_xticks(np.arange(50, 230, 10))\n",
    "\n",
    "ax.set_ylim(0.1, 1.25)\n",
    "ax.set_xlim(85, 220)\n",
    "\n",
    "ax.set_ylabel(r'$L_\\lambda$ [A. U.]')\n",
    "ax.set_xlabel('Rest-frame wavelength [nm]')\n",
    "\n",
    "ax.tick_params(labelsize=17, direction='in', which='both')\n",
    "ax.yaxis.set_ticks_position('both')\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "\n",
    "fig.savefig('../figures/stacked_QSO_all.pdf', bbox_inches='tight', pad_inches=0.1,\n",
    "            facecolor='w')\n",
    "plt.show()\n",
    "pred_flux_all = ufloat(result.eval(x=114), result.eval_uncertainty(x=[114])[0])\n",
    "print(pred_flux_all)\n",
    "meas_flux_all = np.average(sed_50[mask_lyforest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_lum = np.load('ref_lum.npy')\n",
    "ref_wav = np.load('ref_wav.npy')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4.5))\n",
    "\n",
    "cmap = plt.get_cmap('rainbow')\n",
    "norm = np.nanmax(stacked_seds_50[3])\n",
    "\n",
    "iii = 0\n",
    "for wl, sed_50 in zip(wl_list, stacked_seds_50):\n",
    "    this_mask = (to_stack_lya_NB >= nb_list[iii][0]) & (to_stack_lya_NB <= nb_list[iii][1])\n",
    "    this_z_mean = np.mean(to_stack_data['z'][this_mask])\n",
    "\n",
    "    ax.plot(wl, sed_50 / norm,\n",
    "            c=cmap((this_z_mean - 3) / (5 - 3)),\n",
    "            lw=2, zorder=90-iii)\n",
    "    ax.plot([], [],\n",
    "            label=r'$\\bar{z}=$ ' + f'{this_z_mean:0.2f}',\n",
    "            c=cmap((this_z_mean - 3) / (5 - 3)),\n",
    "            lw=4)\n",
    "    iii += 1\n",
    "\n",
    "xx = np.linspace(91, 215, 1000)\n",
    "print(f'UV slope = {result.params['b'].value:0.2f} +/- {result.params['a'].stderr**0.5:0.2f}')\n",
    "ax.plot(xx, QSO_cont(xx, result.params['a'].value, result.params['b'].value) / norm,\n",
    "        lw=2, zorder=-2314098, alpha=0.5, c='r', ls='--')\n",
    "\n",
    "\n",
    "ax.text(92, -0.2, r'LyC')\n",
    "ax.text(103.1, -0.2, r'Ly$\\beta$')\n",
    "ax.text(122.1, -0.2, r'Ly$\\alpha$')\n",
    "ax.text(141, -0.2, 'SiIV\\n+OIV')\n",
    "ax.text(156, -0.2, 'CIV')\n",
    "ax.text(192, -0.2, 'CIII')\n",
    "\n",
    "\n",
    "ax.axvline(91.2, ls=':', c='dimgray', zorder=-99)\n",
    "ax.axvline(154.9, ls=':', c='dimgray', zorder=-99)\n",
    "ax.axvline(121.56, ls=':', c='dimgray', zorder=-99)\n",
    "ax.axvline(102.572, ls=':', c='dimgray', zorder=-99)\n",
    "ax.axvline(139.98, ls=':', c='dimgray', zorder=-99)\n",
    "ax.axvline(190.8734, ls=':', c='dimgray', zorder=-99)\n",
    "\n",
    "ax.axhline(0, c='k')\n",
    "\n",
    "ax.set_xlabel(r'Rest-frame wavelength [nm]')\n",
    "ax.set_ylabel(r'$L_\\lambda$ [A. U.]')\n",
    "ax.legend(ncol=2, fontsize=13, framealpha=1)\n",
    "ax.set_xlim(75, 210)\n",
    "ax.set_ylim(-0.25, 1.25)\n",
    "\n",
    "ax.tick_params(labelsize=17, direction='in', which='both')\n",
    "ax.yaxis.set_ticks_position('both')\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "\n",
    "\n",
    "fig.savefig('../figures/stacked_QSO_zbins.pdf', bbox_inches='tight', pad_inches=0.1,\n",
    "            facecolor='w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IGM_TRANSMISSION(redshift_Arr, A, B):\n",
    "\n",
    "    Transmission_Arr = pow(np.e, A * (1 + redshift_Arr)**B)\n",
    "\n",
    "    return Transmission_Arr\n",
    "\n",
    "def FG_T(redshift_Arr):\n",
    "\n",
    "    A = -0.001845\n",
    "    B = 3.924\n",
    "\n",
    "    Transmission = IGM_TRANSMISSION(redshift_Arr, A, B)\n",
    "\n",
    "    return Transmission\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "T_Arr = []\n",
    "for f, f16, f84 in zip(meas_flux_list, meas_flux_16_list, meas_flux_84_list):\n",
    "    T_Arr.append(ufloat(f, (f84 - f16) * 0.5) / 10**pred_flux_all)\n",
    "\n",
    "\n",
    "z_LyF = 113 * (z_50 + 1) / 121.567 - 1\n",
    "z_LyF_16 = 113 * (z_16 + 1) / 121.567 - 1\n",
    "z_LyF_84 = 113 * (z_84 + 1) / 121.567 - 1\n",
    "\n",
    "ax.errorbar(z_LyF[1:], [t.n for t in T_Arr][1:],\n",
    "            xerr=[(z_LyF - z_LyF_16)[1:], (z_LyF_84 - z_LyF)[1:]],\n",
    "            yerr=[t.s for t in T_Arr][1:],\n",
    "            fmt='s', capsize=2, mfc='lightseagreen',\n",
    "            mec='k', ecolor='k', label='This work',\n",
    "            zorder=9999, ms=6.5)\n",
    "\n",
    "\n",
    "### Literature\n",
    "# Faucher-Giguère+08\n",
    "xx = np.linspace(0, 6, 1000)\n",
    "ax.plot(xx, FG_T(xx), lw=2, ls='--', zorder=-1, color='darkblue',\n",
    "        label='Faucher-Giguère+08 (best-fit)')\n",
    "\n",
    "FG08 = pd.read_csv('/home/alberto/almacen/PAUS_data/T_Lya_forest/FG08.csv', header=None).to_numpy()\n",
    "FG08_z = FG08[::2][:, 0]\n",
    "FG08_T = np.e**-FG08[::2][:, 1]\n",
    "FG08_T_err = np.e**-FG08[::2][:, 1] * (FG08[1::2][:, 1] - FG08[::2][:, 1])\n",
    "ax.errorbar(FG08_z, FG08_T,\n",
    "            yerr=FG08_T_err,\n",
    "            fmt='o', mec='dimgray', mfc='orange',\n",
    "            capsize=2, ecolor='orange',\n",
    "            label='Faucher-Giguère+08')\n",
    "\n",
    "# Becker+13\n",
    "ax.plot(xx, np.e**-(0.751 * ((1 + xx) / (1 + 3.5))**2.9 - 0.132),\n",
    "        lw=2, ls='--', zorder=-1, color='orangered',\n",
    "        label='Becker+13 (best-fit)')\n",
    "\n",
    "B13 = pd.read_csv('/home/alberto/almacen/PAUS_data/T_Lya_forest/B13.csv', header=None).to_numpy()\n",
    "B13_z = B13[::2][:, 0]\n",
    "B13_T = np.e**((-B13[1::2][:, 1] -B13[::2][:, 1]) *  0.5)\n",
    "B13_T_err = -np.e**(-B13[::2][:, 1]) + np.e**-B13[1::2][:, 1]\n",
    "\n",
    "ax.errorbar(B13_z, np.abs(B13_T),\n",
    "            yerr=np.abs(B13_T_err),\n",
    "            fmt='^', mec='dimgray', mfc='orchid',\n",
    "            capsize=2, ecolor='orchid',\n",
    "            label='Becker+13', ms=8)\n",
    "\n",
    "\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "# ax.set_yscale('log')\n",
    "ax.set_xlim(1, 6)\n",
    "\n",
    "ax.set_xlabel('Redshift')\n",
    "ax.set_ylabel('IGM transmission')\n",
    "\n",
    "ax.tick_params(labelsize=17, direction='in', which='both')\n",
    "ax.yaxis.set_ticks_position('both')\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "\n",
    "ax.legend(fontsize=11, frameon=False)\n",
    "\n",
    "fig.savefig('../figures/IGM_Lya_forest_T.pdf', bbox_inches='tight', pad_inches=0.1,\n",
    "            facecolor='w')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
